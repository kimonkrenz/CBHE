---
title: "CBHE Address Matching"
author: "Kimon Krenz"
date: "30/06/2022"
output: html_document
---

# Setup

## Load Required Packages
```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
knitr::opts_chunk$set(echo = TRUE)

## Load all required packages

library(RPostgreSQL)
library(stringr)
library(tidyverse)
library(tidytext)
library(stringdist)
library(dplyr)
library(plyr)

# create "not in" function
`%ni%` <- function(x,y) !(x %in% y) 
```

## Establish Database Connection
```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
## Establish database connection

# create a connection
pw <- {
  "define pw"
}

# loads the PostgreSQL driver
drv <- dbDriver("PostgreSQL")
# creates a connection to the postgres database
# note that "con" will be used later in each connection to the database
con <- dbConnect(drv, dbname = "cbhe_db",
                 host = "localhost", port = 5432,
                 user = "username", password = pw)
rm(pw)# removes the password`enter code here`

# list all tables
#dbListTables(con)
```

# Load Address Data from Files into Postgres

```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
# select source folder
source_path <- "/filepath/Addressdata"

# get list of all files, read all files into list & row bind into single file
x <- base::list.files(path = source_path, pattern = ".csv", full.names = TRUE) %>% lapply(fread) %>% bind_rows %>% rename_with(~ tolower(.x))

y <- gp_matched_full %>% dplyr::distinct_all(.)

# write table to postgres
dbWriteTable(con, "gp_addresses", x, overwrite = TRUE, append = FALSE, row.names = FALSE)

# clean up
rm(source_path,x)
```

# Address Match Functions

## Calculate Single Line Address
```{r}
#' Altered code from NHSBSA Data Analytics https://github.com/nhsbsa-data-analytics/addressMatchR

# function for addressbase premium data
calc_addressbase_premium_single_line_address <- function(
  df,
  include_postcode = FALSE
) {

  # Create the single line address
  df <- dplyr::mutate(df,
        single_line_address = paste0( 
        ifelse(department_name == "", "", paste0(department_name, ", ") ),
        ifelse(organisation_name == "", "", paste0(organisation_name, ", ") ), 
        ifelse(sub_building_name == "", "", paste0(sub_building_name, ", ") ),
        ifelse(building_name == "", "", paste0(building_name, ", ") ),
        ifelse(building_number == "", "", paste0(building_number, ", ") ),
        ifelse(po_box_number == "", "", paste0("PO BOX ", po_box_number, ", ") ),
        ifelse(dependent_thoroughfare == "", "", paste0(dependent_thoroughfare, ", ") ),
        ifelse(thoroughfare == "", "", paste0(thoroughfare, ", ") ),
        ifelse(double_dependent_locality == "", "", paste0(double_dependent_locality, ", ") ),
        ifelse(dependent_locality == "", "", paste0(dependent_locality, ", ") ),
        ifelse(post_town == "", "", paste0(post_town, ", ") )
        ))


  # Add the postcode if necessary
  if (include_postcode) {

    df <- dplyr::mutate(df,
        single_line_address = paste0(single_line_address, postcode)
      )

  }

  df

}

# function tailored for gp addess data
calc_gp_address_single_line_address <- function(
  df,
  include_postcode = FALSE
) {

  # Create the single line address
  df <- dplyr::mutate(df,
        single_line_address = paste0( 
        ifelse(nameofbuilding == "", "", paste0(nameofbuilding, ", ") ),
        ifelse(numberofbuilding == "", "", paste0(numberofbuilding, ", ") ),
        ifelse(nameofroad == "", "", paste0(nameofroad, ", ") ),
        ifelse(nameoflocality == "", "", paste0(nameoflocality, ", ") ),
        ifelse(nameoftown == "", "", paste0(nameoftown, ", ") )
        ))

  # Add the postcode if necessary
  if (include_postcode) {

    df <- dplyr::mutate(df,
        single_line_address = paste0(single_line_address, postcode)
      )

  }

  df

}

```


### Tidy Single Line Address
```{r}
#' Code based on NHSBSA Data Analytics https://github.com/nhsbsa-data-analytics/addressMatchR

# function to tidy single line address data
tidy_single_line_address <- function(df, col) {

df <- df %>%
  # Uppercase
  dplyr::mutate(single_line_address = toupper({{ col }})) %>%
  # replace special characters with a single space
  dplyr::mutate(single_line_address = gsub("[–=+,.();:#''?!%§$´`{}\\/\\*@[\\]\\-\\\\]", " ",{{ col }}, ignore.case = TRUE, perl = TRUE)) %>%
  # add a space between any digit followed by a non-digit (e.g. 1A becomes 1 A)
  dplyr::mutate(single_line_address = gsub("([[:alpha:]])([[:digit:]])", "\\1 \\2",{{ col }}, ignore.case = TRUE, perl = TRUE)) %>%
  # add a space between any non-digit followed by a digit (e.g. A1 becomes A 1)
  dplyr::mutate(single_line_address = gsub("([[:digit:]])([[:alpha:]])", "\\1 \\2",{{ col }}, ignore.case = TRUE, perl = TRUE)) %>%
  # replace the ampersand character with the string "and"
  dplyr::mutate(single_line_address = gsub("&", " AND ",{{ col }}, ignore.case = TRUE, perl = TRUE)) %>%
  # replace any multiple spaces with a single space
  dplyr::mutate(single_line_address = gsub("( ){2,}", " ",{{ col }}, ignore.case = TRUE, perl = TRUE)) %>%
  # remove leading/trailing whitespace
  dplyr::mutate(single_line_address = trimws({{ col }}))

}
```

### Tidy postcode
```{r}
#' Altered code from NHSBSA Data Analytics https://github.com/nhsbsa-data-analytics/addressMatchR

# function to tidy postcode data
tidy_postcode <- function(df, col) {

  # Tide the postcode column
df <- df %>%
  # Uppercase
  dplyr::mutate(postcode = toupper({{ col }})) %>%
  # Remove anything not a character or digit
  dplyr::mutate(postcode = gsub("[^A-Z0-9]", "",{{ col }}, ignore.case = TRUE, perl = TRUE))

}

```

## Tokenize Address Line
```{r}

#' Altered code from NHSBSA Data Analytics https://github.com/nhsbsa-data-analytics/nhsbsaR
#' Basically adapting `tidytext::unnest_tokens`
#' 
#' 
#' @param df Data Table
#' @param col Column to be tokenized
#' @param drop Whether original input column should get dropped
#' @param regex regex to tokenize by

db_unnest_tokens <- function(df, col, drop = TRUE, regex = "[:space:]") {

  df <- tidytext::unnest_tokens(df, "token", col, token = "regex", pattern = regex, format = "text", to_lower = FALSE, drop = TRUE, collapse = NULL) %>% dplyr::mutate(token_number = row.names(.))
  
}

```

## Reduce Input Tables
```{r}
#' Reduce input address tables to three columns
#'
#' @param primary_df Dataframe of distinct primary addresses
#' @param primary_postcode_col Column containing the primary postcode
#' @param primary_address_col Column containing the primary single line address
#' @param lookup_df Dataframe of distinct lookup addresses
#' @param lookup_postcode_col Column containing the lookup postcode
#' @param lookup_address_col Column containing the lookup single line address

input_addresses <- function(
  df,
  postcode,
  address,
  id
) { 

# use only relevant columns

df <- df[,c(id,postcode,address)]

}
```


## Calculate Address Match
```{r}

#' Altered code from NHSBSA Data Analytics https://github.com/nhsbsa-data-analytics/addressMatchR
#' Match two sets of addresses
#'
#' Match a distinct dataframe of primary addresses to a distinct dataframe of
#' lookup addresses.
#'
#' Returns a dataframe of exact matches (postcode and single line address) and
#' non exact matches (postcode and fuzzy single line address). For non exact
#' matches it will retain draws.
#'
#' @param primary_df Dataframe of distinct primary addresses
#' @param primary_postcode_col Column containing the primary postcode
#' @param primary_address_col Column containing the primary single line address
#' @param lookup_df Dataframe of distinct lookup addresses
#' @param lookup_postcode_col Column containing the lookup postcode
#' @param lookup_address_col Column containing the lookup single line address


calc_match_addresses <- function(
  primary_df,
  primary_postcode_col,
  primary_address_col,
  primary_id,
  lookup_df,
  lookup_postcode_col,
  lookup_address_col,
  lookup_id
) {

  # Rename the lookup postcode column name to be the same as the primary
  # postcode column name
  lookup_df <- lookup_df %>%
    dplyr::rename("{primary_postcode_col}" := .data[[lookup_postcode_col]])

  # First step is to do the exact matches. We mock join address column here so
  # that we can do the join easily.
  exact_match_df <-
    dplyr::inner_join(
      x = primary_df %>%
        # Mock a join address column on the primary dataframe
        dplyr::mutate(join_address = .data[[primary_address_col]]),
      y = lookup_df %>%
        # Mock a join address column on the lookup dataframe
        dplyr::mutate(join_address = .data[[lookup_address_col]]),
      by = c(primary_postcode_col, "join_address"),
      suffix = c("", "_lookup"),
      copy = TRUE
    ) %>%
    dplyr::select(-join_address)

  # Now get the rows that haven't already been matched
  non_exact_match_df <- primary_df %>%
    dplyr::anti_join(
      y = exact_match_df,
      na_matches = "na",
      copy = TRUE,
      by = primary_address_col
    )

  # Filter non exact matches to postcodes in the lookup
  non_exact_match_df <- non_exact_match_df %>%
    dplyr::semi_join(
      y = lookup_df %>%
        dplyr::select(.data[[primary_postcode_col]]),
      copy = TRUE,
      by = primary_postcode_col
    )

  # Tokenise non exact match addresses
  non_exact_match_df <- non_exact_match_df %>%
    db_unnest_tokens(col = primary_address_col, drop = FALSE) %>%
    dplyr::mutate(token_weight = ifelse(grepl("[0-9]", token), 4, 1))

  # Add the theoretical max score for each non exact match address
  non_exact_match_df <- non_exact_match_df %>%
    dplyr::group_by(across(-c(token_number, token, token_weight))) %>%
    dplyr::mutate(max_score = sum(token_weight, na.rm = TRUE)) %>%
    dplyr::ungroup()

  # Tokenise lookup addresses
  lookup_df <- lookup_df %>%
    db_unnest_tokens(col = lookup_address_col, drop = FALSE) %>%
    dplyr::select(-token_number) %>%
    dplyr::distinct() %>%
    dplyr::mutate(token_weight = ifelse(grepl("[0-9]", token), 4, 1))

  # We want to minimise the amount of Jaro–Winkler calculations we do. So first
  # do the exact token level matches
  non_exact_match_exact_match_df <- non_exact_match_df %>%
    dplyr::inner_join(
      y = lookup_df,
      by = c(primary_postcode_col, "token_weight", "token"),
      suffix = c("", "_lookup"),
      copy = TRUE
    ) %>%
    dplyr::mutate(token_lookup = token)

  # Now get the remaining candidates to consider for Jaro–Winkler matching
  # (character token types that aren't an exact match)
  non_exact_match_jw_match_df <- non_exact_match_df %>%
    dplyr::inner_join(
      y = lookup_df,
      by = c(primary_postcode_col, "token_weight"),
      suffix = c("", "_lookup"),
      copy = TRUE
    ) %>%
    dplyr::filter(
      token_weight == 1,
      token != token_lookup
    )

  # We can also apply some other filters
  non_exact_match_jw_match_df <- non_exact_match_jw_match_df %>%
    dplyr::filter(
      # Tokens share the same first letter
      substr(token_lookup, 1, 1) == substr(token, 1, 1) |
        # Tokens share same second letter
        substr(token_lookup, 2, 2) == substr(token, 2, 2) |
        # Tokens share same last letter
        substr(token_lookup, nchar(token_lookup), nchar(token_lookup)) == substr(token, nchar(token_lookup), nchar(token_lookup)) |
        # One token is a substring of the other
        stringr::str_detect(token_lookup, token) |
        stringr::str_detect(token, token_lookup)
    )

  # Now calculate the jarrow winkler scores
  non_exact_match_jw_match_df <- non_exact_match_jw_match_df %>%
    dplyr::mutate(score = stringdist::stringsim(token, token_lookup, method = "jw", p = 0))

  # And filter to scores above 0.8
  non_exact_match_jw_match_df <- non_exact_match_jw_match_df %>%
    dplyr::filter(score > 0.8)

  # Now stack the non exact exact and Jaro–Winkler matches back together
  non_exact_match_df <- dplyr::union_all(
    x = non_exact_match_exact_match_df %>%
      dplyr::mutate(score = 1),
    y = non_exact_match_jw_match_df
  )

  # Multiply the score by the token weight
  non_exact_match_df <- non_exact_match_df %>%
    dplyr::mutate(score = score * token_weight)

  # Get the max score for each primary token in the primary address from each
  # lookup address
  non_exact_match_df <- non_exact_match_df %>%
    dplyr::group_by(dplyr::across(-c(token_lookup, score))) %>%
    dplyr::summarise(score = max(score, na.rm = TRUE)) %>%
    dplyr::ungroup()

  # Sum the score for each single line address combination
  non_exact_match_df <- non_exact_match_df %>%
    dplyr::group_by(
      dplyr::across(-c(token_number, token, token_weight, score))
    ) %>%
    dplyr::summarise(score = sum(score, na.rm = TRUE)) %>%
    dplyr::ungroup()

  # Normalise the score
  non_exact_match_df <- non_exact_match_df %>%
    dplyr::mutate(score = score / max_score) %>%
    dplyr::select(-max_score)

  # Take the top scoring lookup address for each primary address (if there are
  # draws then keep all of them)
  non_exact_match_df <- non_exact_match_df %>%
    dplyr::group_by(
      .data[[primary_postcode_col]], .data[[primary_address_col]]
    ) %>%
    dplyr::slice_max(order_by = score) %>%
    dplyr::ungroup()

  # Stack the exact and non exact matches together and output
  dplyr::union_all(
    x = exact_match_df %>%
      dplyr::mutate(score = 1, match_type = "exact"),
    y = non_exact_match_df %>%
      dplyr::mutate(match_type = "non-exact")
  )

}

```

# Load Data from Postgres

## Get AddressBase Premium
```{r message=FALSE, warning=FALSE, paged.print=FALSE}

df_ab <- dbGetQuery(con,
  paste0("
SELECT 	uprn, 
		department_name, 
		organisation_name, 
		sub_building_name, 
		building_name, 
		building_number,
		po_box_number,
		dependent_thoroughfare,
		thoroughfare,
		double_dependent_locality,
		dependent_locality,
    post_town,
    postcode
		FROM abp_blpu

    LEFT JOIN public.abp_delivery_point USING (uprn);
 ")
  
) %>% 
  dplyr::mutate(across(where(anyNA), ~ replace_na(.,""))) %>% 
  calc_addressbase_premium_single_line_address(., include_postcode = FALSE) %>% 
  tidy_single_line_address(., single_line_address) %>% 
  tidy_postcode(., postcode)

```

## Get GP Addresses
```{r message=FALSE, warning=FALSE, paged.print=FALSE}

df_gp <- dbGetQuery(con,
  paste0("
SELECT 	*, fullpostcode AS postcode
		FROM gp_addresses;
")
  
) %>% 
  dplyr::mutate(across(where(anyNA), ~ replace_na(.,""))) %>% 
  calc_gp_address_single_line_address(., include_postcode = FALSE) %>% 
  tidy_single_line_address(., single_line_address) %>% 
  tidy_postcode(., postcode)

```

## Prepare Input
```{r}

# AddressBase Premium
df_ab <- input_addresses(df_ab, "postcode", "single_line_address", "uprn") %>% dplyr::filter(., single_line_address != "", postcode != "")

# GP Addresses
df_gp_m <- input_addresses(df_gp, "postcode", "single_line_address", "rowidentifier") %>% dplyr::distinct(postcode, single_line_address, .keep_all = TRUE) %>% dplyr::filter(., single_line_address != "", postcode != "")

# Split into n equal parts
df_gp_s <- split(df_gp_m, factor(sort(rank(row.names(df_gp_m)) %% 5 # specify number of equal parts
                                      )))
```

# Match Addresses

## Generate Output
```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
# Create emtpy list
matched <- list()

# Loop over GP address parts for better performance
for (i in 1:length(df_gp_s)) {
  
matched[[i]]  <-  calc_match_addresses(
  df_gp_s[[i]], "postcode", "single_line_address", "rowidentifier",
  df_ab, "postcode", "single_line_address", "uprn"
                )

}

# clean up
rm(df_gp_m, df_gp_s)

# bind list entries by row
matched <- dplyr::bind_rows(matched)

# write resulting table to postgres
dbWriteTable(con, "gp_matched", matched, overwrite = TRUE, append = FALSE, row.names = FALSE)

# sort table remove redundant information
matched <- matched %>%
  dplyr::arrange(desc(score), match_type, postcode, single_line_address) %>% 
  dplyr::distinct(single_line_address, .keep_all = TRUE) #%>% 
  #dplyr::filter(score >= 0.7)

df_gp_matched <- dplyr::left_join(df_gp, matched[,c("uprn","score","match_type","single_line_address","single_line_address_lookup")], by = "single_line_address")

# write resulting table to postgres
dbWriteTable(con, "gp_matched_full", df_gp_matched, overwrite = TRUE, append = FALSE, row.names = FALSE)

```
